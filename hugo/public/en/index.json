[{"authors":["admin"],"categories":null,"content":"Hello!\nMy name is Luis Cacho I am a Computer Systems Engineer. I define myself as a Linux enthusiast who loves to work and experiment with Open Source technologies while I am learning about it and trying to apply best practices and my problem solving skills.\nI am currently working as a Linux System Administrator in Rackspace headquarters, based in San Antonio, TX, US.\nI like share the expertise that I have acquired trougth the years in this blog.\n","date":1571956976,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1574020722,"objectID":"2525497d367e79493fd32b198b28f040","permalink":"/en/authors/admin/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/en/authors/admin/","section":"authors","summary":"Hello!\nMy name is Luis Cacho I am a Computer Systems Engineer. I define myself as a Linux enthusiast who loves to work and experiment with Open Source technologies while I am learning about it and trying to apply best practices and my problem solving skills.\nI am currently working as a Linux System Administrator in Rackspace headquarters, based in San Antonio, TX, US.\nI like share the expertise that I have acquired trougth the years in this blog.","tags":null,"title":"Luis Cacho","type":"authors"},{"authors":["Luis Cacho"],"categories":["molecule","ansible"],"content":"","date":1571956976,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571956976,"objectID":"3b86150c17cb389360a2448543e5ad5b","permalink":"/en/project/molecule-cookiecutter/","publishdate":"2019-10-24T17:42:56-05:00","relpermalink":"/en/project/molecule-cookiecutter/","section":"project","summary":"","tags":["molecule","ansible","roles","cookiecutter","code","development"],"title":"Molecule Cookiecutter","type":"project"},{"authors":["Luis Cacho"],"categories":["ansible"],"content":"aasdasdasdasd\n","date":1571899343,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571899343,"objectID":"86ccaaabc1d24061dcadcc36fad289f9","permalink":"/en/project/ansible-galaxy-roles/","publishdate":"2019-10-24T01:42:23-05:00","relpermalink":"/en/project/ansible-galaxy-roles/","section":"project","summary":"Ansible roles for the community","tags":["ansible","galaxy","project","roles","code","development"],"title":"Ansible Galaxy Roles","type":"project"},{"authors":["Luis Cacho"],"categories":["SysAdmin","DevOps","Open Source","Docker","Linux","Security","Cloud Native"],"content":" Table of Contents HAHAHUGOSHORTCODE-TOC0-HBHB\nDocker Login the right Way Hi again!\nIt is been a while since I wrote something here, as always, there is no much time for a hobby.\nI\u0026rsquo;ve been working for a while with docker, not a production level, but for some applications that I use at work. And since the Docker Hub Data breach I put more atention on the security of my data/credentials, so I investigate a little about and found this official repository https://github.com/docker/docker-credential-helpers/ from Docker where are the supported credential helpers.\nCredential Store Docker keeps our credentials saved on a JSON file located on ~/.docker/config.json, but unfortunatelly credentials are just encrypted on base64, here is an articule/video where there is an explanation for the why it is a bad idea to just use base64 encryption.\nThe following is a diagram on how a plain text storage works:\nHere is an exampleon how ~/.docker/config.json looks like when is using plain text credentials:\ncat ~/.docker/config.json { \u0026quot;auths\u0026quot;: { \u0026quot;https://index.docker.io/v1/\u0026quot;: { \u0026quot;auth\u0026quot;: \u0026quot;azRjaDA6c3VwZXJzZWNyZXRwYXNzd29yZAo=\u0026quot; }, \u0026quot;quay.io\u0026quot;: { \u0026quot;auth\u0026quot;: \u0026quot;azRjaDA6c3VwZXJzZWNyZXRwYXNzd29yZAo=\u0026quot; } }, \u0026quot;HttpHeaders\u0026quot;: { \u0026quot;User-Agent\u0026quot;: \u0026quot;Docker-Client/18.09.6 (linux)\u0026quot; } }  After a successful docker login command, Docker stores a base64 encoded string from the concatenation of the username, a colon, and the password and associates this string to the registry the user is logging into:\n$ echo azRjaDA6c3VwZXJzZWNyZXRwYXNzd29yZAo= | base64 -d - k4ch0:supersecretpassword  A docker logout command removes the entry from the JSON file for the given registry:\n$ docker logout quay.io Remove login credentials for quay.io $ cat ~/.docker/config.json { \u0026quot;auths\u0026quot;: { \u0026quot;https://index.docker.io/v1/\u0026quot;: { \u0026quot;auth\u0026quot;: \u0026quot;azRjaDA6c3VwZXJzZWNyZXRwYXNzd29yZAo=\u0026quot; } }, \u0026quot;HttpHeaders\u0026quot;: { \u0026quot;User-Agent\u0026quot;: \u0026quot;Docker-Client/18.09.6 (linux)\u0026quot; } }  Docker Credential Helpers Since docker version 1.11 implements support from an external credential store for registry authentication. That means we can use a native keychain of the OS. Using an external store is more secure than storing on a \u0026ldquo;plain text\u0026rdquo; Docker configuration file.\nIn order to use a external credential store, we need a program to interact with.\nThe actual list of \u0026ldquo;official\u0026rdquo; Docker Credential Helper is:\n docker-credential-osxkeychain: Provides a helper to use the OS X keychain as credentials store. docker-credential-secretservice: Provides a helper to use the D-Bus secret service as credentials store. docker-credential-wincred: Provides a helper to use Windows credentials manager as store. docker-credential-pass: Provides a helper to use pass as credentials store.  docker-credential-secretservice On this post we will explore the docker-credential-secretservice and how to configure it.\n We need to download and install the helper. You can find the lastest release on https://github.com/docker/docker-credential-helpers/releases.\nDownload it, extract it and make it executable.\nwget https://github.com/docker/docker-credential-helpers/releases/download/v0.6.2/docker-credential-secretservice-v0.6.2-amd64.tar.gz tar -xf docker-credential-secretservice-v0.6.2-amd64.tar.gz chmod +x docker-credential-secretservice sudo mv docker-credential-secretservice /usr/local/bin/  Then, we need to specify the credential store in the file ~/.docker/config.json to tell docker to use it.\nThe value must be the one after the prefix docker-credential-. In this case:\n{ \u0026quot;credsStore\u0026quot;: \u0026quot;secretservice\u0026quot; }   To facilite the configuration and do not make mistakes, you can run:\nsed -i '0,/{/s/{/{\\n\\t\u0026quot;credsStore\u0026quot;: \u0026quot;secretservice\u0026quot;,/' ~/.docker/config.json  From now we are uning an external store, so if you are currently logged in, you must run docker logout to remove the credentials from the file and run docker login tostart using the new ones.\nLet me know how this works for you.\nReferences: https://github.com/docker/docker-credential-helpers\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\nhttps://www.slideshare.net/DavidYeung22/can-we-stop-saving-docker-credentials-in-plain-text-now\n","date":1557950322,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574020722,"objectID":"2550a6b6b1e3ef22f904f2d225585395","permalink":"/docker-login-the-right-way/","publishdate":"2019-05-15T13:58:42-06:00","relpermalink":"/docker-login-the-right-way/","section":"post","summary":"How to configure a docker-credential-helpers to keep docker credentials safe on Linux","tags":["DevOps","SysAdmin","Docker","Open Source","Linux","Security","Cloud Native"],"title":"Docker Login the Right Way","type":"post"},{"authors":[],"categories":["SysAdmin","DevOps","Open Source","Rackspace"],"content":"Table of Contents HAHAHUGOSHORTCODE-TOC0-HBHB\nSometimes it is necessary to delete all the content of the Cloud Files containers, however, the API does not have a proper method to delete the data and the containers on the same API call. Also, accoring to the documentation, you can only delete empty containers.\nSo, in cases where you need to delete the data and the containers at the same time, you should follow the next steps:\n Download Turbolift, I know it is an old tool.\ngit clone https://github.com/cloudnull/turbolift cd turbolift  In order to get and isolated installation, we are going to create a Python Virtual Environment (virtualenv)\nmkvirtualenv turbolift workon turbolift  Install the tool\npip install turbolift  Now, prior to start to play with the API calls, we need to grab some data to authenticate with the API:\n   Variable Definition     USERNAME This is the Rackspace Public Cloud username   APIKEY This is your API-KEY   REGION This is the Region where the Cloud Files are located (dfw, ord, iad, lon, hkg)   TOKEN The TOKEN is generated after you get authenticated   ENDPOINT This ENDPOINT is given also after you get authenticated    Next step, we are going to use cURL, to perform all the API calls:\n First of all, get the TOKEN:\nUSERNAME=YOUR-USERNAME APIKEY=YOUR-APIKEY TOKEN=$(curl -s -XPOST https://identity.api.rackspacecloud.com/v2.0/tokens \\ -d'{\u0026quot;auth\u0026quot;:{\u0026quot;RAX-KSKEY:apiKeyCredentials\u0026quot;:{\u0026quot;username\u0026quot;:\u0026quot;'$USERNAME'\u0026quot;,\u0026quot;apiKey\u0026quot;:\u0026quot;'$APIKEY'\u0026quot;}}}' \\ -H\u0026quot;Content-type:application/json\u0026quot; | jq '.access.token.id' | tr -d \u0026quot;\\\u0026quot;\u0026quot;)  Next step, get the ENDPOINT:\nENDPOINT=$(curl -s -XPOST https://identity.api.rackspacecloud.com/v2.0/tokens \\ -d'{\u0026quot;auth\u0026quot;:{\u0026quot;RAX-KSKEY:apiKeyCredentials\u0026quot;:{\u0026quot;username\u0026quot;:\u0026quot;'$CL_USERNAME'\u0026quot;,\u0026quot;apiKey\u0026quot;:\u0026quot;'$APIKEY'\u0026quot;}}}' \\ -H\u0026quot;Content-type:application/json\u0026quot; | jq '.access.serviceCatalog[] | select((.name==\u0026quot;cloudFiles\u0026quot;) or (.name==\u0026quot;cloudFilesCDN\u0026quot;)) | {name} + .endpoints[] | .publicURL' | tr -d \u0026quot;\\\u0026quot;\u0026quot; | grep -v cdn | grep -i $REGION)   In this case we are skipping all te CDN endpoints, but you can add them if is necessary.\n With all the collected data, next step is use turbolift to delete the Cloud Files container and their data. To do it, I use a for-loop:\nfor i in $(curl -s -H \u0026quot;X-Auth-Token: $TOKEN\u0026quot; $ENDPOINT); do turbolift -u $USERNAME -a $APIKEY --os-rax-auth $REGION delete -c $i ; done   Now, you have all the Data and Cloud Files containers deleted on one region.\nüòÑ\n","date":1550086624,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574019424,"objectID":"2d842e881f30fcd3bf741bcb87a9f9f4","permalink":"/bulk-delete-cloud-files-api/","publishdate":"2019-02-13T13:37:04-06:00","relpermalink":"/bulk-delete-cloud-files-api/","section":"post","summary":"How to delete the Data and Cloud Files Containers using Rackspace Cloud Files API, cURL and Turbolift","tags":["Openstack","DevOps","Sysadmin","Turbolift","Open Source","Rackspace Public Cloud","Cloud Files"],"title":"Bulk Delete Rackspace Cloud Files data via API","type":"post"},{"authors":["Luis Cacho"],"categories":["SysAdmin","DevOps","Network"],"content":"Table of Contents HAHAHUGOSHORTCODE-TOC0-HBHB\nI just have a Ruckus ICX 7150 Switch on my home and I\u0026rsquo;m trying to get access under ssh and web, to easy configuration and security instead of use telnet. So, I logged in using telnet and then run the following commands to configure a username/password and begin to receive petirions over port 22(ssh) and port 443(https). Let\u0026rsquo;s begin!\n We will connect via telnet to the switch.\ntelnet SWITCH_IP  Once we are on the Switch CLI as a optional step, we can configure an IP on the switch.\ndevice\u0026gt; enable device# configure terminal device(config)# ip address IP_ADDRESS/CIDR device(config)# ip default-gateway IP_GATEWAY  Now, the next steps are for generate a SSL certificate, a username/password, activate password to login and enable thw web access and ssh access.\ndevice(config)# crypto-ssl certificate generate device(config)# username USERNAME password PASSWORD device(config)# aaa authentication login default local device(config)# aaa authentication web-server default local  It may take several minutes to generate the certificate key. After that, save the configuration.\ndevice(config)# write memory   Now you are able to login on your switch using ssh or web.\nSource: https://robrobstation.com/2017/07/17/ruckus-icx7150-c12p-initial-configuration/\n","date":1542741343,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574018143,"objectID":"f4dda011ee14c2fab766fd371b99d29e","permalink":"/configure-ruckus-switch/","publishdate":"2018-11-20T13:15:43-06:00","relpermalink":"/configure-ruckus-switch/","section":"post","summary":"Steps to configure ssh and webaccess on a Ruckus Switch","tags":["Ruckus","DevOps","SysAdmin","Network"],"title":"Configure SSH on a Ruckus Switch","type":"post"},{"authors":["Luis Cacho"],"categories":["SysAdmin","DevOps","Open Source"],"content":"I been working since last year using Ansible for fun and to trying to get prepared to become a DevOps, so I found an excelent OpenStack project called ARA Records Ansible.\nBasically it is a project from the OpenStack community that makes it easier to understand and troubleshoot your Ansible roles and playbooks.\nIf you want more information, please refer to the Documentation Page.\nAnyhow, I just found a little bug on the Ansible Role to install ARA ansible-role-ara on Debian based distros and just send the patch to fixit.\nHere is the link to my contribution.\nAnd, as I am proud of my first commit on a big project here is the screenshot too:\nI feel happy and motivated to still learn about this Open Source project and a lot more.\nüòÑ\n","date":1521137056,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574013856,"objectID":"9e854b946c25f4a12632dc84150e15af","permalink":"/my-first-contribution-to-openstack/","publishdate":"2018-03-15T12:04:16-06:00","relpermalink":"/my-first-contribution-to-openstack/","section":"post","summary":"I'm proud to perform my first contribution to a OpenStack project","tags":["Openstack","DevOps","SysAdmin","Ansible","ARA","Git","Open Source"],"title":"My First Contribution to OpenStack project","type":"post"},{"authors":["Luis Cacho"],"categories":["SysAdmin","Linux","Storage"],"content":" I\u0026rsquo;ve just noticed that my NAS a Western Digital My Cloud EX2 is going slower, so I decided to investigate about what can I do to improve its performance.\nI assume that you already configure ssh on your NAS device. If is not configured you can follow the next instructions: https://support.wdc.com/knowledgebase/answer.aspx?ID=14952\nStop Indexing Services /etc/init.d/wdmcserver stop /etc/init.d/wdphotodbmerger stop  To do it forever, you should create the cronjob as:\ncrontab -e  And add the following lines:\n@reboot /bin/sh /etc/init.d/wdmcserverd stop @reboot /bin/sh /etc/init.d/wdphotodbmerger stop  ","date":1518802218,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574011818,"objectID":"d1008797fd844834fafb9bb75978bd09","permalink":"/improve-wd-mycloud-performance/","publishdate":"2018-02-16T11:30:18-06:00","relpermalink":"/improve-wd-mycloud-performance/","section":"post","summary":"How to improve performance on a WD MyCloud EX2","tags":["Network","Storage","SysAdmin","NAS"],"title":"Improve WD MyCloud performance","type":"post"},{"authors":["Luis Cacho"],"categories":["Network"],"content":"If anyone need a good OSI Model cheat sheet, as me:\n","date":1505319539,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574007539,"objectID":"aceec65c34ac01c2df1a2e521d139dcd","permalink":"/osi-model-cheat-sheet/","publishdate":"2017-09-13T10:18:59-06:00","relpermalink":"/osi-model-cheat-sheet/","section":"post","summary":"Network OSI Model","tags":["Network","Training"],"title":"OSI Model Cheat Sheet","type":"post"},{"authors":["Luis Cacho"],"categories":["DevOps","Linux","SysAdmin","Rackspace"],"content":" Hi again,\nAs many of you know a lot of \u0026ldquo;Production\u0026rdquo; applications need to be configured to provide High Availability. With that in mind, a best practice architecture to your application is to add a Load Balancer as a front end who distribute your traffic between your application nodes, as you can appreciate on the next image:\nSSL Offloading In this case, my \u0026ldquo;Production\u0026rdquo; application is my blog, and I will install a SSL Certificate on the Cloud Load Balancer(CLB) to offloading the encryption/decryption to the CLB instead of doing it on the webserver. That way your webservers uses port 80 (HTTP), as always, and you serve your content trought port 443(HTTPS).\nHere are the what I use to configure my WordPress with SSL Certificate:\n SSL Certificate issued using Let\u0026rsquo;s Encrypt A Client of Let\u0026rsquo;s Encrypt called acme A Cloud Load Balancer A WordPress installation  Step 1: Install acme.sh client There is a lot of ACME clients supported by Let\u0026rsquo;s Encrypt, the most popular is Certbot. However, I prefer to use acme.sh.\nLet\u0026rsquo;s install it:\ngit clone https://github.com/Neilpang/acme.sh.git cd acme.sh # Create a data home directory sudo mkdir -p /opt/acme/data # Actual command to install it bash acme.sh --install --home /opt/acme --config-home /opt/acme/data --certhome /opt/acme/data/ssl-certs --accountemail your@email.com  Step 2: Issue SSL Certificate Once acme.sh is installed, we proceed to issue our first SSL Certificate:\n/opt/acme/acme.sh --issue -d example.com -w /var/www/vhosts/example.com/public_html [Mon Aug 25 06:04:07 UTC 2017] Creating domain key [Mon Aug 25 06:04:07 UTC 2017] The domain key is here: /opt/acme/data/ssl-certs/example.com/example.com.key [Mon Aug 25 06:04:07 UTC 2017] Single domain='example.com' [Mon Aug 25 06:04:07 UTC 2017] Getting domain auth token for each domain [Mon Aug 25 06:04:07 UTC 2017] Getting webroot for domain='example.com' [Mon Aug 25 06:04:07 UTC 2017] Getting new-authz for domain='example.com' [Mon Aug 25 06:04:08 UTC 2017] The new-authz request is ok. [Mon Aug 25 06:04:08 UTC 2017] Verifying:example.com [Mon Aug 25 06:04:11 UTC 2017] Success [Mon Aug 25 06:04:11 UTC 2017] Verify finished, start to sign. [Mon Aug 25 06:04:11 UTC 2017] Cert success. -----BEGIN CERTIFICATE----- MIIE/zCCA+egAwIBAgISA2AIs/G8gWjkRkNOUb7zmqh1MA0GCSqGSIb3DQEBCwUA MEoxCzAJBgNVBAYTAlVTMRYwFAYDVQQKEw1MZXQncyBFbmNyeXB0MSMwIQYDVQQD ExpMZXQncyBFbmNyeXB0IEF1dGhvcml0eSBYMzAeFw0xNzA4MjgwNTA0MDBaFw0x NzExMjYwNTA0MDBaMBkxFzAVBgNVBAMTDmNvb2tpZWxhYnMubmV0MIIBIjANBgkq hkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAo8/4fXH0dOHcSlyXpsBoULhwQYkz4m0J MegRHU2mhyy/jfKWM6KHDxHpFWUFajLJ/ORE4uncvjmRYeSVBxgv2R2cYoZyKd6v txT+Cdj3jD9fBfDerfdfsdfsd6Y6mlr6Im61afKsFXIgLsprBpK22JU6HOz+0Fdo lan09aaF8zLPtVzdfJw9MU55K7nzerxO8j4ro2lve0PHExkMIBCrXey50wcuqQRY hwkbbXsm+wTES7TCn3tooSzFq6ore3JrSckxhFQ96EOea0s9CgYnw4d9rU/b3jyK bFCILEJK64vgFHx0qvd0hBJFJG/HUtAXAVrFQjjlZlCmCMbnee1UTQIDAQABo4IC DjCCAgowDgYDVR0pasoasoasogWgMB0GA1UdJQQWMBQGCCsGAQUFBwMBBggrBgEF BQcDAjAMBgNVHRMBAf8EAjAAMB0GA1UdDgQWBBR2KRpXKKgTorwfXpo44wgKyFUl QzAfBgNVHSMEGDAWgBSoSmpjBH3duubRObemRWXv86jsoTBvBggrBgEFBQcBAQRj MGEwLgYIKwYBBQUHMAASdTdddHA6Ly9vY3NwLmludC14My5sZXRzZW5jcnlwdC5v cmcwLwYIKwYBBQUHMAKGI2h0dHA6Ly9jZXJ0LmludC14My5sZXRzZW5jcnlwdC5v cmcvMBkGA1UdEQQSMBCCDmNvb2tpZWxhYnMubmV0MIH+BgNVHSAEgfYwgfMwCAYG Z4EMAQIBMIHmBgsrBgEEAYLfEwEBATCB1jAmBggrBgEFBQcCARYaaHR0cDovL2Nw cy5sZXRzZW5jcnlwdC5vcmcwgasGCCsGAQUFBwICMIGeDIGbVGhpcyBDZXJ0aWZp Y2F0ZSBtYXkgb25seSBiZSByZWxpZWQgdXBvbiBieSBSZWx5aW5nIFBhcnRpZXMg YW5kIG9ubHkgaW4gYWNjb3JkYW5jZSB3aXRoIHRoZSBDZXJ0aWZpY2F0ZSBQb2xp Y3kgZm91bmQgYXQgaHR0cHM6Ly9sZXRzZW5jcnlwdC5vcmcvcmVwb3NpdG9yeS8w DQYJKoZIhvcNAQELBQADggEBAFVGs82tzyVER6U0x7p/Q+6xplDFd6ap/dVX9G6i eRPf4ayGykPSH9J3ewu398LOQd3DE93oWbqc7PfEC40Z5HqvCEY3fl9auep99/IF rwhf36J7PXvEsPrUB6pxNFSBw9WX366Z1MP8qoIzm3XYEpp2D/SPniWY5+eQ42Pj WNxxVksA4kFUF9wgKcrsCNTm0X8GZj5HUXC1OwtlopY2w42QrAMGwz1jM4nxv5Mc Jim+nT0zmJUhAdQi8ocDjAl2PvcfdgfmkMr9IWH3al/GJSKy3a9Cq+BaIsIUYi6E 8M8Mj+00ONNn1folm9aVn+FW5fVCaxYN32ir8PnoTWkOXK8= -----END CERTIFICATE----- [Mon Aug 25 06:04:11 UTC 2017] Your cert is in /opt/acme/data/ssl-certs/example.com/example.com.cer [Mon Aug 25 06:04:11 UTC 2017] Your cert key is in /opt/acme/data/ssl-certs/example.com/example.com.key [Mon Aug 25 06:04:11 UTC 2017] The intermediate CA cert is in /opt/acme/data/ssl-certs/example.com/ca.cer [Mon Aug 25 06:04:11 UTC 2017] And the full chain certs is there: /opt/acme/data/ssl-certs/example.com/fullchain.cer  Where the explained options are:\n-issue: Issue a new certificate\n-d (-domain) : Specifies a domain, used to issue, renew or revoke, etc.\n-w (-webroot) : Specifies the web root folder for web root mode. This is the DocumentRoot where your site is hosted and it is necessary to verify it by Let\u0026rsquo;s Encrypt.\nStep 3: Install SSL Certificate on Cloud Load Balancer So, at this moment we have our SSL Certificate, Private Key, and Intermediate CA Certificate ready to install on our Cloud Load Balancer (CLB)\nYour cert is in /opt/acme/data/ssl-certs/example.com/example.com.cer Your cert key is in /opt/acme/data/ssl-certs/example.com/example.com.key The intermediate CA cert is in /opt/acme/data/ssl-certs/example.com/ca.cer  So we should go to https://mycloud.rackspace.com -\u0026gt; Rackspace Cloud -\u0026gt; Networking -\u0026gt; Cloud Load Balancers:\nThen, to Optional Features and Enable/Configure on \u0026ldquo;Secure Traffic SSL\u0026rdquo;\nFinally, we add our SSL Certificate, Private Key, and Intermediate CA Certificate to the CLB and save the configuration:\nStep 4: Configure WordPress We are almost done, at this time we already have configured our SSL on the CLB to provide WordPress over HTTPS, however, WordPress is still with HTTP, so we need to reconfigure our WordPress with SSL.\nDatabase queries First of all, we should update the links from http to https; we are going to do it directly on the database doing the following queries:\nWarning: Change all instances of example.com to your own. If you have the www as part of your WordPress Address(URL) in the WordPress Settings, add the \u0026lsquo;www\u0026rsquo;.\nAlso, if you have a custom table prefix in the WordPress database, something other than the default \u0026lsquo;wp\u0026rsquo;, then you must change all the instances of \u0026lsquo;wp\u0026rsquo; to your own table prefix.\n Update any embedded attachments/img that use http:This one updates the src attributes that use double quotes:\nUPDATE `wp_posts` SET post_content = REPLACE(post_content, 'src=\\\u0026quot;http://example.com', \\ 'src=\\\u0026quot;https://example.com') WHERE post_content LIKE '%src=\\\u0026quot;http://example.com%';  This one takes care of any src attributes that use single quotes:\nUPDATE `wp_posts` SET post_content = REPLACE(post_content, 'src=\\'http://example.com', \\ 'src=\\'https://example.com') WHERE post_content LIKE '%src=\\'http://example.com%';  Update any hard-coded URLs for links.This one updates the URL for href attributes that use double quotes:\nUPDATE `wp_posts` SET post_content = REPLACE(post_content, 'href=\\\u0026quot;http://example.com', \\ 'href=\\\u0026quot;https://example.com') WHERE post_content LIKE '%href=\\\u0026quot;http://example.com%';  This one updates the URL for href attributes that use single quotes:\nUPDATE `wp_posts` SET post_content = REPLACE(post_content, 'href=\\'http://example.com', \\ 'href=\\'https://example.com') WHERE post_content LIKE '%href=\\'http://example.com%';  Update any \u0026ldquo;pinged\u0026rdquo; links:\nUPDATE `wp_posts` SET pinged = REPLACE(pinged, 'http://example.com', \\ 'https://example.com') WHERE pinged LIKE '%http://example.com%';  This step is just a confirmation step to make sure that there are no remaining http URLs for your site in the wp_posts table, except the GUID URLs.\nYou must replace WP_DB_NAME, near the beginning of the query, with the name of your database.\nThis will confirm that nowhere in the wp_posts table is there a remaining http URL, outside of the GUID column. This ignores URLs in the GUID column.\nThis query only searches; it does not replace anything, nor make any changes. So, this is safe to run. It‚Äôs a safe and quick way to check the wp_posts table while ignoring the guid column.\nThis SQL query should return an empty set. That would mean that it found no http URLs for your site. (This is all just 1 query. It‚Äôs 1 very, very long line.)\nWarning:¬†Remember to replace WP_DB_NAME, near the beginning of the query, with the name of your database.\nSELECT * FROM `WP_DB_NAME`.`wp_posts` WHERE (CONVERT(`ID` USING utf8) LIKE \\ '%%http://example.com%%' OR CONVERT(`post_author` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`post_date` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`post_date_gmt` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`post_content` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`post_title` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`post_excerpt` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`post_status` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`comment_status` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`ping_status` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`post_password` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`post_name` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`to_ping` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`pinged` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`post_modified` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`post_modified_gmt` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`post_content_filtered` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`post_parent` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`menu_order` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`post_type` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`post_mime_type` USING utf8) LIKE '%%http://example.com%%' \\ OR CONVERT(`comment_count` USING utf8) LIKE '%%http://example.com%%');  Now, we move to the wp_comments table. This changes any comment author URLs that point to the http version of your site. This is in case you‚Äôve ever replied to a comment while your URL was pointing to http.\nUPDATE `wp_comments` SET comment_author_url = REPLACE(comment_author_url, \\ 'http://example.com', 'https://example.com') WHERE comment_author_url \\ LIKE '%http://example.com%';  This updates the content of the comments on your site. If there are any links in the comments that are linking to an http URL on your site, they will be updated to https.\nUPDATE `wp_comments` SET comment_content = REPLACE(comment_content, 'http://example.com', \\ 'https://example.com') WHERE comment_content LIKE '%http://example.com%';  Now we move to the wp_postmeta table. This takes care of any custom post meta that points to the http version of your site.\nUPDATE `wp_postmeta` SET `meta_value` = REPLACE(meta_value, 'http://example.com', \\ 'https://example.com') WHERE meta_value LIKE '%http://example.com%';  Now we move to the wp_options table. Update the ‚ÄúWordPress Address (URL)‚Äù and ‚ÄúSite Address (URL)‚Äù.\nFor the WordPress Address URL, you may have to modify example.com. If you have WordPress installed in some other directory, then modify this according to your own WordPress URL. For example, some people have WordPress installed in a subdirectory named ‚Äúblog‚Äù, and so their WordPress Address would be https://example.com/blog.\nUPDATE `wp_options` SET `option_value` = \u0026quot;https://example.com\u0026quot; \\ WHERE `wp_options`.`option_name` = 'siteurl';  This one will update the Site Address URL (this is the home page of your site):\nUPDATE `wp_options` SET `option_value` = \u0026quot;https://example.com\u0026quot; \\ WHERE `wp_options`.`option_name` = 'home';   WordPress Control Panel Besides, with run the queries directly on the database, we can update, or verify,¬†the blog URLs, by going to Settings \u0026gt; General\nAnd updating your WordPress Address (URL) and Site Address (URL) address fields.\nWordPress Config File Finally, we should add the following line to our wp_config.php file\n$_SERVER['HTTPS']='on';  Now, you have configured WordPress with Let\u0026rsquo;s Encrypt SSL Certificate on a Load Balancer.\n","date":1504452407,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1574004407,"objectID":"95f11ecd630be10823ea17f2c595faa1","permalink":"/","publishdate":"2017-09-03T09:26:47-06:00","relpermalink":"/","section":"post","summary":"How to configure Wordpress with a Let's Encrypt SSL Certificate on a Load Balancer","tags":["Wordpress","SSL","Let's Encrypt","Load Balancer","Rackspace Public Cloud","DevOps"],"title":"WordPress with Let's Encrypt SSL Certificate on a Load Balancer","type":"post"},{"authors":["Luis Cacho"],"categories":["DevOps","Rackspace","SysAdmin"],"content":"This time I\u0026rsquo;ve want to create a homemade Server with my Raspberry Pi2 and publish it using my own sub-domain, the main problem is that the ISP provide me an dynamic IP and we should ensure that if my IP address change the sub-domain record should point to the new IP.\nThe instructions assume that you:\n Have a domain\n Have already changed your NS records to point to dns1.stabletransit.com and dns2.stabletransit.com.\n   You should download the latest version of rsdns from github\ncd ~/bin/ git clone https://github.com/linickx/rsdns.git  Go to your Rackspace portal (https://mycloud.rackspace.com/) and grab your Username \u0026amp; API key (It\u0026rsquo;s under \u0026ldquo;Your Account\u0026rdquo; -\u0026gt; \u0026ldquo;Account Settings\u0026rdquo; -\u0026gt; \u0026ldquo;API Key\u0026rdquo;)\n Create a configuration file for rsdns (~/.rsdns_config) with your settings.\n#!/bin/bash RSUSER=lcacho RSAPIKEY=1234567890 RSPATH=~/bin/rsdns/  You need your domain created on Rackspace(It\u0026rsquo;s under \u0026ldquo;Networking\u0026rdquo; -\u0026gt; \u0026ldquo;Cloud DNS\u0026rdquo; -\u0026gt; \u0026ldquo;Create Domain\u0026rdquo;) if you don\u0026rsquo;t have your domain created you are able to created using rsdns:\n./rsdns-domain.sh -d www.luiscachog.io -e lcacho@luisachog.io  Once you have a domain setup you need to create an A record. To create the A record you going to need an IP address, you can use http://icanhazip.com to get your actual current IP. Again to create a record you are able to do it from Rackspace panel (It\u0026rsquo;s under \u0026ldquo;Networking\u0026rdquo; -\u0026gt; \u0026ldquo;Cloud DNS\u0026rdquo; -\u0026gt; YOUR_DOMAIN -\u0026gt; \u0026ldquo;Add Record\u0026rdquo;) or you can use rsdns:\n./rsdns-a.sh -n dynamic-host.luiscachog.io -i 123.123.123.123 -t 3600   In the above the TTL is set to 1hr (3600 secs), this is so that DNS caches do not keep the record too long. That\u0026rsquo;s all the pre-work done, now lets get your dynamic host setup!\n The script to update your a record is rsdns-dc.sh, and you run it like this:\n./rsdns-dc.sh -n dynamic-host.luiscachog.io   The script uses icanhazip to get your current IP, it then update the A record with it.\nI never switch off my router so I have create a created a cronjob to run that script every 2 hours, plus the 1hr TTL should mean that the record is roughly in sync with my IP without making unnecessary requests\n7.- I use CentOS, so I can simply drop the following file called rsdns-dc into /etc/cron.d/ with this\u0026hellip;\nvim /etc/cron.d/rsdns-dc * */2 * * * lcacho /home/lcacho/bin/rsdns/rsdns-dc.sh -n dynamic-host.luiscachog.io \u0026amp;\u0026gt;/dev/null  Now we are done! Private Dynamic DNS on your own zone using the Rackspace API.\n","date":1460359488,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573629888,"objectID":"91de0edd405b4198fa7d87d658391c47","permalink":"/build-a-dynamc-dns-client-with-rackspace-api/","publishdate":"2016-04-11T01:24:48-06:00","relpermalink":"/build-a-dynamc-dns-client-with-rackspace-api/","section":"post","summary":"How to Build a Dynamic DNS via API","tags":["API","DevOps","DNS","Rackspace Public Cloud"],"title":" Build a Dynamic DNS Client with Rackspace API","type":"post"},{"authors":["Luis Cacho"],"categories":["Linux","SysAdmin"],"content":"When you configure spamassassin on VestaCP (CentOS) sometimes you might have some problems with the autolearn feature and also with the bayes plugin of spamassassin.\nThe error looks like:\nmore /var/log/maillog Apr 5 00:31:00 vestaserver01 spamd[1353]: spamd: connection from localhost [127.0.0.1] at port 37022 Apr 5 00:31:00 vestaserver01 spamd[1353]: spamd: setuid to nobody succeeded Apr 5 00:31:00 vestaserver01 spamd[1353]: spamd: creating default_prefs: //.spamassassin/user_prefs Apr 5 00:31:00 vestaserver01 spamd[1353]: config: cannot create user preferences file //.spamassassin/user_prefs: No such file or directory Apr 5 00:31:00 vestaserver01 spamd[1353]: spamd: failed to create readable default_prefs: //.spamassassin/user_prefs Apr 5 00:31:00 vestaserver01 spamd[1353]: spamd: checking message \u0026amp;lt;5520C87B.8020009@example.com\u0026amp;gt; for nobody:99 Apr 5 00:31:00 vestaserver01 spamd[1353]: plugin: eval failed: bayes: (in learn) locker: safe_lock: cannot create tmp lockfile /.spamassassin/bayes.lock.vestaserver01.example.com.1353 for /.spamassassin/bayes.lock: No such file or directory Apr 5 00:31:00 vestaserver01 spamd[1353]: spamd: clean message (-1.0/5.0) for nobody:99 in 0.2 seconds, 3138 bytes. Apr 5 00:31:00 vestaserver01 spamd[1353]: spamd: result: . 0 - ALL_TRUSTED,HTML_MESSAGE scantime=0.2,size=3138,user=nobody,uid=999,required_score=5.0,rhost=localhost,raddr=127.0.0.1,rport=37022,mid=\u0026amp;lt;5520C87B.8020009@example.com\u0026amp;gt;,autolearn=unavailable  Basically the error are the permissions on: //.spamassassin/user_prefs\nTo fix it follow the next steps:\n Create the user spamd, in order to avoid to run spamassassin with the user nobody:\ngroupadd -g 1001 spamd useradd -u 1001 -g spamd -s /sbin/nologin -d /var/lib/spamassassin spamd mkdir /var/lib/spamassassin chown spamd:spamd /var/lib/spamassassin\u0026lt;/pre\u0026gt;  Edit the file /etc/exim/exim.conf.\nvi /etc/exim/exim.conf   Change the line:\nspam = nobody:true/defer_ok  to\nspam = spamd:true/defer_ok   Restart exim an spamassassin\n/etc/init.d/exim restart /etc/init.d/spamassassin restart  After that verify that the files bayes_seen, bayes_toks and user_prefs exists on the spamd home (In this case /var/lib/spamassassin)\npwd /var/lib/spamassassin ls -la total 40 drwxr-xr-x 3 spamd spamd 4096 Apr 7 17:58 . drwxr-xr-x 36 root root 4096 Feb 25 00:56 .. -rw------- 1 spamd spamd 12288 Apr 2 21:34 bayes_seen -rw------- 1 spamd spamd 12288 Apr 2 17:34 bayes_toks -rw-r--r-- 1 spamd spamd 1869 Apr 1 17:18 user_prefs   Done!\n","date":1428475178,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573627178,"objectID":"6923b91e27942140331b4fbf3067505a","permalink":"/spamassassin-error-on-vestacp-centos/","publishdate":"2015-04-08T00:39:38-06:00","relpermalink":"/spamassassin-error-on-vestacp-centos/","section":"post","summary":"How to fix an Spamassasin Error on a VestaCP","tags":["Email","Exim","Spamassassin","VestaCP"],"title":"Spamassassin Error: cannot create user preferences file //.spamassassin/user_prefs: Permission denied on VestaCP - CentOS","type":"post"},{"authors":["Luis Cacho"],"categories":["Linux","SysAdmin"],"content":"To configure your server to use a jailed user on SFTP you should do:\n Edit the sshd_config file   We need to comment the following line:\nSubsystem sftp /usr/libexec/openssh/sftp-server  And add the uncomment line, your modification will be same as:\n# Subsystem sftp /usr/libexec/openssh/sftp-server Subsystem sftp internal-sftp  Also, at the end of the file we should to add the next lines:\nMatch Group sftponly ChrootDirectory %h X11Forwarding no AllowTCPForwarding no ForceCommand internal-sftp  After save all the changes, we must restart the sshd daemon\nservice sshd restart   Add sftponly group\ngroupadd sftponly  Add jailed user and add to sftponly group\nuseradd -m USERNAME passwd USERNAME usermod -aG sftponly,apache USERNAME  IMPORTANT: Create directory and establish correct permissions\nchown root:root /home/USERNAME chmod 755 /home/USERNAME mkdir /home/USERNAME/TEST.DOMAIN.COM chown apache:apache /home/USERNAME/TEST.DOMAIN.COM chmod 775 /home/USERNAME/TEST.DOMAIN.COM mkdir /var/www/vhost/TEST.DOMAIN.COM chown apache:apache /var/www/vhost/TEST.DOMAIN.COM chmod 775 /var/www/vhost/TEST.DOMAIN.COM   If you have any connection problem please double check the permissions on the folders and check the logs on /var/log/secure\ntail -f /var/log/secure   Mount DocumentRoot path on jailed user home directory\nmount -o bind,noatime /var/www/vhost/TEST.DOMAIN.COM/ /home/USERNAME/TEST.DOMAIN.COM  Make the mount point permanent, editing the fstab file:\nvi /etc/fstab\u0026lt;/pre\u0026gt;   Add the mount point at the end of the file:\n/var/www/vhost/TEST.DOMAIN.COM/ /home/USERNAME/TEST.DOMAIN.COM none bind,noatime 0 0  Save and exit\n Test connection:\nsftp SERVERIP   ","date":1427862132,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573618932,"objectID":"1523318f11ee09a23d086cdcd01a3816","permalink":"/sftp-jailed/","publishdate":"2015-03-31T22:22:12-06:00","relpermalink":"/sftp-jailed/","section":"post","summary":"How to configure a FTP Secured and Jailed","tags":["SSH","SFTP"],"title":"SFTP Jailed","type":"post"},{"authors":["Luis Cacho"],"categories":["Linux","SysAdmin","Rackspace","Cloud"],"content":"When you use the Rackspace Cloud Load Balancers, it is common that the IP logged in Apache is the Private IP (ServiceNet) from the Cloud Load Balancer, however, we can fix that.\nWe can view sources IP\u0026rsquo;s in Apache Logs doing some changes on Apache configuration file and also on the vhosts configuration files.\nOn your Apache configuration file, you should to find the line:\nLogFormat \u0026quot;%h %l %u %t \\\u0026quot;%r\\\u0026quot; %\u0026amp;gt;s %b \\\u0026quot;%{Referer}i\\\u0026quot; \\\u0026quot;%{User-Agent}i\\\u0026quot;\u0026quot; combined  Modified to:\nLogFormat \u0026quot;%{X-Forwarded-For}i %h %l %u %t \\\u0026quot;%r\\\u0026quot; %\u0026amp;gt;s %O \\\u0026quot;%{Referer}i\\\u0026quot; \\\u0026quot;%{User-Agent}i\\\u0026quot;\u0026quot; combined  And also, on your vhosts configuration files you should to change the \u0026ldquo;combined\u0026rdquo; LogFormat definition will then be called in a \u0026ldquo;CustomLog\u0026rdquo; entry specific to your VirtualHost configuration. Here is an example VirtualHost definition to show you what I\u0026rsquo;m referring to:\nServerAdmin webmaster@example.com DocumentRoot /var/www/html/example.com ServerName example.com ErrorLog logs/example.com-error_log CustomLog logs/example.com-access_log combined  After adding the X-Forwarded-For definition to the LogFormat definition, you can restart Apache and view the logs to notice the difference. If all is done properly, you will see an actual public IP in the first field of your logs instead of the Cloud Load Balancer IP.\n","date":1423811324,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573542524,"objectID":"eb80a639a83270331ae0b151faebaa9d","permalink":"/view-sources-ips-apache-logs-behind-loadbalancer/","publishdate":"2015-02-12T02:08:44-05:00","relpermalink":"/view-sources-ips-apache-logs-behind-loadbalancer/","section":"post","summary":"How to configure Apache Logs to view the source IP's when it is behind a Load Balancer","tags":["DevOps","Apache","LoadBalancer","Rackspace Public Cloud"],"title":"View sources IP's in Apache Logs behind a Load Balancer","type":"post"},{"authors":["Luis Cacho"],"categories":["SysAdmin"],"content":"Sometimes, I\u0026rsquo;m having problems with my Mac, when it\u0026rsquo;s sleep (hibernate) and I tried to \u0026ldquo;wake up\u0026rdquo; the Mac doesn\u0026rsquo;t start, and it shows me a Black Screen. So, I\u0026rsquo;ve rebooted and after that it is stuck on the boot process.\nSo, I\u0026rsquo;ve found these solution to avoid that Yosemite stuck on the boot process:\nA. Enter to Single-user or verbose mode\n Shutdown the Mac\n Press the power button to start the computer\n Immediately press and hold the Command Key and either of the following\n the \u0026ldquo;s\u0026rdquo; key for single-user mode (Command-S) the \u0026ldquo;v\u0026rdquo; key for verbose mode (Command-V)   B. When you login on the Mac, you should run the following commands:\n/sbin/mount -uw / rm -rf /System/Library/Caches/* rm /private/var/db/BootCache.playlsit reboot  After the reboot, your Mac will boot as always.\nüôÇ\n","date":1420698406,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573194406,"objectID":"5324a41fa2bf24220246e845c2799aeb","permalink":"/yosemite-stuck-boot-process/","publishdate":"2015-01-08T00:26:46-06:00","relpermalink":"/yosemite-stuck-boot-process/","section":"post","summary":"How to avoid that your MacOS Yosemite stuck on the boot process","tags":["MacOS"],"title":"Yosemite stuck on boot process","type":"post"},{"authors":["Luis Cacho"],"categories":["SysAdmin","Wordpress"],"content":"I\u0026rsquo;ve purchased some themes on ThemeForest.com because they\u0026rsquo;re great. So this time I want to write about \u0026ldquo;How to Update ThemeForest Themes with the Envato WordPress Toolkit\u0026rdquo;.\nFirst of all, Envato WordPress Toolkit it is very similar to a WordPress plugin. The installation it is the only difference. So I will explain how install the \u0026ldquo;plugin\u0026rdquo; and how to use in order to get the last update from your theme.\n Envato WordPress Toolkit is NOT available on WordPress Repositories, so you will to download from Github. https://github.com/envato/envato-wordpress-toolkit\n After you download the .ZIP file, you should be able to install from the WordPress Plugin Manager. Or you could upload the \u0026ldquo;envato-wordpress-toolkit\u0026rdquo; folder to the \u0026ldquo;/wp-content/plugins/\u0026rdquo;\u0026rdquo; directory.\n Activate the Plugin from the WordPress Plugin Manager.\n You will need to generate an API key from your Themeforest account.\n  4.1. In order to get your API key from Themeforest, you should login to themeforest.com, go to your dashboard and click on \u0026#8220;My Settings\u0026#8221; The API Keys screen allows you to generate a free API key.\n Once the API connection has been established you will see a list of themes that can be auto installed. If you don\u0026rsquo;t see any themes and are certain you\u0026rsquo;ve done everything correct, there is a good chance the theme author has not updated their theme to be available for auto install and update. If that\u0026rsquo;s the case, please contact the theme author and ask them to update their theme\u0026rsquo;s information.  This \u0026ldquo;plugin\u0026rdquo; very helpful to get your themes updated. I hope works for you as well as with me.\n","date":1415600804,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573194404,"objectID":"79d652e4a07ebfac4e2b35351a6d7956","permalink":"/update-themeforest-themes-envato-wordpress-toolkit/","publishdate":"2014-11-10T02:08:44-05:00","relpermalink":"/update-themeforest-themes-envato-wordpress-toolkit/","section":"post","summary":"How to install and manage the Envato WordPress Toolkit","tags":["Wordpress"],"title":"How to Update a ThemeForest Theme with the Envato WordPress Toolkit","type":"post"},{"authors":["Luis Cacho"],"categories":["Linux","SysAdmin"],"content":"Hello,\nThis time I share with you the faster and more secure method to reset the root password of MySQL.\nThis method is faster because the downtime is between 1 or 2 seconds (MySQL restart time) and it is more secure because the mysqld is not started without grants on the tables.\nThe steps are:\n Create text file /var/lib/mysql/mysql-init with the sintaxis to reset the password for user root:\nvim /var/lib/mysql/mysql-init  SET PASSWORD FOR 'root'@'localhost' = PASSWORD('new_password');  Add under the [mysqld] stanza on the file /etc/my.cnf:\ninit-file=/var/lib/mysql/mysql-init  Restart the mysqld service:\nservice mysqld restart  Remove the init-file line from /etc/my.cnf\n Remove /var/lib/mysql/mysql-init\nrm /var/lib/mysql/mysql-init    And after that, you can access again to your mysql instance.  :)\n","date":1406701607,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573194407,"objectID":"3887b763a740919dc4629d842eb24840","permalink":"/mysql-reset-root-password/","publishdate":"2014-07-30T02:08:44-05:00","relpermalink":"/mysql-reset-root-password/","section":"post","summary":"How to reset a root MySQL password","tags":["MySQL"],"title":"MySQL reset root password","type":"post"},{"authors":["Luis Cacho"],"categories":["DevOps","Linux","SysAdmin"],"content":" \nThe common form to log in to MySQL server, is running a mysql command with your login credentials and server\u0026rsquo;s IP address as arguments. For example:\nmysql -u $MYSQL_ROOT -p$MYSQL_PASS  However, besides the inconvenience of typing extra arguments, using plain-text login credentials in a command line like above is really not a secure way to access a MySQL server.\nMySQL offers a way for you to log in to MySQL server without password, by using an external MySQL configuration file. In Linux, there are two different kinds of MySQL configuration files:\n /etc/my.cnf and ~/.my.conf\n  While any system-wide MySQL configuration is defined in /etc/my.cnf, any user-specific MySQL configuration is stored in ~/.my.cnf. You can leverage ~/.my.cnf, to define your MySQL login credential in the file.\nvim ~/.my.cnf  We put our MySQL user in the configuration file:\n[client] user=root password=$PASSWORD_ROOT  Make sure to have the configuration file readable to you only.\nchmod 0600 ~/.my.cnf  Once ~/.my.cnf is created, simply typing mysql command will let you log in to the MySQL server as root, and you no longer need to provide login password separately.\nmysql Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 14787 Server version: 5.1.73 Source distribution Copyright (c) 2000, 2013, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql\u0026gt;  ","date":1397545724,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1573196924,"objectID":"c019ef79639d840d5912d6185ebf3fb8","permalink":"/mysql-without-password/","publishdate":"2014-04-15T02:08:44-05:00","relpermalink":"/mysql-without-password/","section":"post","summary":"How to configure a file to access mysql without password","tags":["MySQL"],"title":"MySQL without password","type":"post"},{"authors":["Luis Cacho"],"categories":["DevOps","Featured","Rackspace"],"content":"  \nSince January 6th I working on Rackspace, the Open Cloud Company, so I\u0026rsquo;m a Racker almost 3 months ago and I\u0026rsquo;m loving every minute of it.\nPrevious Everything stared on November 2013 when a Technical Recruiter contact me and started a proceess with some long tough interviews, ability tests, paperwork, etc; I have accepted a position as a Linux System Administrator I in the LATAM Team for Rackspace, so, I got to work for one of the most dynamic, fanatic, and fun tech companies in the world!\nSo, I was very excited, nervous, happy, all together.\nThe Castle Since I came to The Castle, everything was wonderful, I have met nice, friendly, smart and fanatical people, like @SugarBear, a Rackspace Ambassador of Culture, or Graham Weston, Rackspace\u0026rsquo;s Chairman and Co-Funder, I met them at the Rookie Orientation (a.k.a Rookie\u0026rsquo;O), where I spend time with other Rookies learning about Rackspace history, culture and future plans.\nOn the Rookie\u0026rsquo;O, I was surprised and admired with all the energy that is transmitted between the new Rackers, it was awesome!\nAnd I was inspired by the Rackspace Core Values:\n Fanatical Support¬Æ in all we do. Results first, substance over flash. Committed to Greatness Full Disclosure and Transparency Passion for our Work Treat fellow Rackers like Friends and Family  Which from my point of view I can applied to my personal life, and having great results.\nAlso is very comfortable to have a Coffe Shop, a soda machine or microwaves inside the Castle. It is pretty nice!\nIn general the first week in Rackspace, on the Rookie\u0026rsquo;O, I was a great experience, I can say that is one of my best experiences in my life.\nMy Goals This is a new big challenge, because means:\n Relocation in other country, specifically in San Antonio, TX, USA. Leave my family in Mexico City, that means that I see my parents only for Skype or FaceTime :). Know other culture, the \u0026ldquo;American\u0026rdquo; culture, with the Breakfast Tacos or Tex-Mex food (I really hate the Tex-Mex food yiack!) or the Lunch at noon, the people do not always says \u0026ldquo;Good morning\u0026rdquo; and some details that I don\u0026rsquo;t understand but here is common. Improve my skills in other language (English) event though I\u0026rsquo;m in the Rackspace LATAM team all the communications like emails or meetings are in English, so, it is very important for my job. And the most important challenge for me is still learn about Linux, get my Red Hat Certifications, do my best at job and take advantage of this great opportunity. All of that to try to be a DevOps Engineer  I will be working on, providing Fanatical Support for our customers, resolving LATAM customer issues with Linux and working with remote teams from all around the world.\nSummarizing, I\u0026rsquo;m a happy Racker üôÇ\n","date":1396249724,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1571900924,"objectID":"7bc1ce4c51e7dcb03184948dff531a4c","permalink":"/im-a-racker/","publishdate":"2014-03-31T02:08:44-05:00","relpermalink":"/im-a-racker/","section":"post","summary":"My early days experience at Rackspace","tags":["DevOps","Featured"],"title":"I'm a Racker","type":"post"}]